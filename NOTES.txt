DATA

sc google sheet ids: 
	644 GSE
	68 E-MTAB
	26 PRJ
	19 SCP
	12 SRP
	
NCBI Entrez Query
	esearch
	efetch

no more than 3 per second. large jobs weekends, weekdays 9pm-5am

SRA file format?
prefetch and fasterq-dump still supported?


DESIGN

Daemons:
-- query 
	queries for new, removes finished. ?

-- download
	takes list of ids, find metadata, download runs

-- analysis
	run starsolo on runs

-- statistics
	calculate and store statistics on individual runs/experiments/projects
	
-- aggregate
	calculate and store aggregate statistics for *all* datasets. 

Directories:
temp:  		immediately delete after usage. system local. 
cache:  	deletable whenever   system local or network filesystem (depending on size, IO).  
metadata:	retained metadata. can be re-downloaded
statistics: calculated values. cannot be recreated without re-running pipeline. 


NOTES

Not doing file locking on input/output files because 1) there is no good file locking
mechanism that works on NFS and 2) items (temporarily, until next run) missing from a file 
doesn't really cause a problem. Each stage will always compare an inlist to what it can 
see is already done. Data missing just delays action. 


TESTING
time to download 5 run .sra files. 
~35 minutes for 24GB (3 + 4 + 6 + 6 + 5 )







 


